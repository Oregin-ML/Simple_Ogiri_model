{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Simple_Ogiri_Model.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1xQ1-c5XbKjkwB4dtyCGv_8b6aE_o84sz","authorship_tag":"ABX9TyO7jt0/k3ylubyKLii7d5V5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"cYqf9HCwhTOA"},"source":["!git clone https://github.com/rinnakk/japanese-pretrained-models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xx8IpqhNZPAL"},"source":["%cd /content/japanese-pretrained-models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0DuEfHKCZhzC"},"source":["!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRwHhpLSZA1j","executionInfo":{"status":"ok","timestamp":1629967531991,"user_tz":-540,"elapsed":16314,"user":{"displayName":"Junya Suzuki","photoUrl":"","userId":"06887977346027627558"}},"outputId":"6ff46efd-5cf2-4675-f597-fad2e02c13d7"},"source":["import torch\n","from transformers import T5Tokenizer, RobertaForMaskedLM\n","\n","# load tokenizer\n","tokenizer = T5Tokenizer.from_pretrained(\"rinna/japanese-roberta-base\")\n","tokenizer.do_lower_case = True  # due to some bug of tokenizer config loading\n","\n","# load model\n","model = RobertaForMaskedLM.from_pretrained(\"rinna/japanese-roberta-base\")\n","model = model.eval()\n","\n","print('#'*40)\n","print('答えさせたい内容を「〜、何。」と聞いてみてください。')\n","print('例；世界一うるさい人と言ったら、何。')\n","print('※最後の「。」を忘れずに。')\n","print('#'*40)\n","\n","# original text\n","text = input()\n","\n","# prepend [CLS]\n","text = \"[CLS]\" + text\n","\n","if '何' in text:\n","  # tokenize\n","  tokens = tokenizer.tokenize(text)\n","  # mask a token\n","  masked_idx = -2\n","  tokens[masked_idx] = tokenizer.mask_token\n","  print('#'*40)\n","  print('#以下の[MASK]の部分を考えます。')\n","  print(tokens)  \n","  print('#'*40)\n","# convert to ids\n","  token_ids = tokenizer.convert_tokens_to_ids(tokens)\n","\n","  # convert to tensor\n","  token_tensor = torch.tensor([token_ids])\n","\n","  # get the top 10 predictions of the masked token\n","\n","  with torch.no_grad():\n","      outputs = model(token_tensor)\n","      predictions = outputs[0][0, masked_idx].topk(10)\n","\n","  print('#'*40)\n","  print('#思いついた答えは・・・')\n","  for i, index_t in enumerate(predictions.indices):\n","      index = index_t.item()\n","      token = tokenizer.convert_ids_to_tokens([index])[0]\n","      print(i, token)\n","  print('#以上です。')\n","  print('#'*40)\n","\n","else:\n","  print('何か聞いてくれないとわからないです。')  \n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["########################################\n","答えさせたい内容を「〜、何。」と聞いてみてください。\n","例；世界一うるさい人と言ったら、何。\n","※最後の「。」を忘れずに。\n","########################################\n","世界一の天才と言ったら、何。\n","########################################\n","#以下の[MASK]の部分を考えます。\n","['[CLS]', '▁', '世界一', 'の', '天才', 'と言った', 'ら', '、', '[MASK]', '。']\n","########################################\n","########################################\n","#思いついた答えは・・・\n","0 アインシュタイン\n","1 あなた\n","2 <unk>\n","3 チャップリン\n","4 ドラえもん\n","5 わからない\n","6 織田信長\n","7 誰か\n","8 サッカー選手\n","9 天才\n","#以上です。\n","########################################\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uAp0TFCdoKCy","executionInfo":{"status":"ok","timestamp":1629967531995,"user_tz":-540,"elapsed":22,"user":{"displayName":"Junya Suzuki","photoUrl":"","userId":"06887977346027627558"}}},"source":[""],"execution_count":26,"outputs":[]}]}